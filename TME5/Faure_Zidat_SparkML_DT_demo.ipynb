{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "SparkDataframe-CSV-solution",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 620345572627578
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "710d6dff-49b3-4ff2-8082-441223d45842"
        },
        "id": "OyxZGhX_gpjy"
      },
      "source": [
        "* Master DAC - BDLE\n",
        "* Author: Mohamed-Amine Baazizi\n",
        "* Affiliation: LIP6 - Faculté des Sciences - Sorbonne Université\n",
        "* Email: mohamed-amine.baazizi@lip6.fr\n",
        "* October 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Setup (with Deequ enabled)"
      ],
      "metadata": {
        "id": "VlBYMn_k-OQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q pyspark==3.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI2R6xl5Xe4r",
        "outputId": "6abd4a88-3440-4089-c74d-a0c947fc6d2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SPARK_VERSION\"] = \"3.3\""
      ],
      "metadata": {
        "id": "35MP8_FUgk1x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  --upgrade -q pydeequ"
      ],
      "metadata": {
        "id": "WHYTd61aXXWc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list|grep pydeequ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMAU1vmKgV_i",
        "outputId": "f69cff58-2adc-466d-a7b4-05be9044ad61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pydeequ                          1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "import pydeequ\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "    .master(\"local\")\\\n",
        "    .appName(\"pyDeequ\")\\\n",
        "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\\\n",
        "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "MbG4BePjX_PY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "id": "i_fTgRavDCRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "0f3eccb6-49be-4107-e848-6793b508d205"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79ce0e31df00>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5c30ed3188f0:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyDeequ</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSlT0zf_s94I"
      },
      "source": [
        "# ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hohU-y8e_tdY"
      },
      "source": [
        "## vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpHimpfYtbGR"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9hO7zlD-34v",
        "outputId": "a7a51ef2-19a8-435e-98f3-40cf217dc880"
      },
      "source": [
        "vec1 = Vectors.dense(1.0, 1.0, 18.0)\n",
        "vec2 = Vectors.dense(0.0, 2.0, 20.0)\n",
        "vec3 = Vectors.sparse(3,[0.0,2.0],[1.0,18.0])\n",
        "vec4 = Vectors.sparse(3,[0.0,1.2,2.0],[2.0,3.0,11.0])\n",
        "vectors = spark.sparkContext.parallelize([vec1,vec2,vec3,vec4])\n",
        "vectors.collect()\n",
        "# vectors.printSchema()\n",
        "# vectors.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DenseVector([1.0, 1.0, 18.0]),\n",
              " DenseVector([0.0, 2.0, 20.0]),\n",
              " SparseVector(3, {0: 1.0, 2: 18.0}),\n",
              " SparseVector(3, {0: 2.0, 1: 3.0, 2: 11.0})]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjomDqxaDSPq"
      },
      "source": [
        "## DT data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpVQt1BaDR20",
        "outputId": "82ab294e-4ac5-47a7-f31e-ee0ebfc83462"
      },
      "source": [
        "tuples = [(\"young\",\"high\",\"no\",\"fair\",\"no\"),\n",
        "               (\"young\",\"high\",\"no\",\"excellent\",\"no\"),\n",
        "               (\"middle\",\"high\",\"no\",\"fair\",\"yes\"),\n",
        "               (\"senior\",\"medium\",\"no\",\"fair\",\"yes\"),\n",
        "               (\"senior\",\"low\",\"yes\",\"fair\",\"yes\"),\n",
        "               (\"senior\",\"low\",\"yes\",\"excellent\",\"no\"),\n",
        "               (\"middle\",\"low\",\"yes\",\"excellent\",\"yes\"),\n",
        "               (\"young\",\"medium\",\"no\",\"fair\",\"no\"),\n",
        "               (\"young\",\"low\",\"yes\",\"fair\",\"yes\"),\n",
        "               (\"senior\",\"medium\",\"yes\",\"fair\",\"yes\"),\n",
        "               (\"young\",\"medium\",\"yes\",\"excellent\",\"yes\"),\n",
        "               (\"middle\",\"medium\",\"no\",\"excellent\",\"yes\"),\n",
        "               (\"middle\",\"high\",\"yes\",\"fair\",\"yes\"),\n",
        "               (\"senior\",\"medium\",\"no\",\"excellent\",\"no\")]\n",
        "print(len(tuples))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9JoybcFDtIg",
        "outputId": "827d0489-c593-4683-9008-4392ab8b8cf0"
      },
      "source": [
        "schema = 'age string, income string, student string, credit_rating string, label string'\n",
        "data = spark.sparkContext.parallelize(tuples).toDF(schema)\n",
        "data.printSchema()\n",
        "data.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            " |-- student: string (nullable = true)\n",
            " |-- credit_rating: string (nullable = true)\n",
            " |-- label: string (nullable = true)\n",
            "\n",
            "+------+------+-------+-------------+-----+\n",
            "|   age|income|student|credit_rating|label|\n",
            "+------+------+-------+-------------+-----+\n",
            "| young|  high|     no|         fair|   no|\n",
            "| young|  high|     no|    excellent|   no|\n",
            "|middle|  high|     no|         fair|  yes|\n",
            "|senior|medium|     no|         fair|  yes|\n",
            "|senior|   low|    yes|         fair|  yes|\n",
            "|senior|   low|    yes|    excellent|   no|\n",
            "|middle|   low|    yes|    excellent|  yes|\n",
            "| young|medium|     no|         fair|   no|\n",
            "| young|   low|    yes|         fair|  yes|\n",
            "|senior|medium|    yes|         fair|  yes|\n",
            "| young|medium|    yes|    excellent|  yes|\n",
            "|middle|medium|     no|    excellent|  yes|\n",
            "|middle|  high|    yes|         fair|  yes|\n",
            "|senior|medium|     no|    excellent|   no|\n",
            "+------+------+-------+-------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clLZvql7dEXf"
      },
      "source": [
        "## Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtg9yaErDM4A"
      },
      "source": [
        "### String indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xek3MwP3VlEF"
      },
      "source": [
        "from  pyspark.ml.feature import StringIndexer"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtUd5I-GCnHF",
        "outputId": "8634851f-6d29-4512-f29c-c836500985d3"
      },
      "source": [
        "field = 'age'\n",
        "age_indexer = StringIndexer(inputCol=field,outputCol='indexed_'+field)\n",
        "df_age_idx = age_indexer.fit(data).transform(data)\n",
        "df_age_idx.show()\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+-------------+-----+-----------+\n",
            "|   age|income|student|credit_rating|label|indexed_age|\n",
            "+------+------+-------+-------------+-----+-----------+\n",
            "| young|  high|     no|         fair|   no|        1.0|\n",
            "| young|  high|     no|    excellent|   no|        1.0|\n",
            "|middle|  high|     no|         fair|  yes|        2.0|\n",
            "|senior|medium|     no|         fair|  yes|        0.0|\n",
            "|senior|   low|    yes|         fair|  yes|        0.0|\n",
            "|senior|   low|    yes|    excellent|   no|        0.0|\n",
            "|middle|   low|    yes|    excellent|  yes|        2.0|\n",
            "| young|medium|     no|         fair|   no|        1.0|\n",
            "| young|   low|    yes|         fair|  yes|        1.0|\n",
            "|senior|medium|    yes|         fair|  yes|        0.0|\n",
            "| young|medium|    yes|    excellent|  yes|        1.0|\n",
            "|middle|medium|     no|    excellent|  yes|        2.0|\n",
            "|middle|  high|    yes|         fair|  yes|        2.0|\n",
            "|senior|medium|     no|    excellent|   no|        0.0|\n",
            "+------+------+-------+-------------+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91WoptYoV3oD"
      },
      "source": [
        "def string_index_cols(cols,prefix):\n",
        "  outCols = map(lambda c:prefix+c, cols)\n",
        "  # return list(outCols)\n",
        "  return StringIndexer(inputCols=cols,outputCols=list(outCols))\n",
        "\n",
        "\n",
        "# si = index_cols(['age','income'])\n",
        "# si.getOutputCols()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7-FDmGhgzeB",
        "outputId": "c8c02bd7-be15-4416-c34a-c15b71ec6ef4"
      },
      "source": [
        "prefix = 'indexed_'\n",
        "fields = ['age','income']\n",
        "age_income_indexer = string_index_cols(fields,prefix)\n",
        "df_age_income_idx = age_income_indexer.fit(data).transform(data)\n",
        "df_age_income_idx.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+-------------+-----+-----------+--------------+\n",
            "|   age|income|student|credit_rating|label|indexed_age|indexed_income|\n",
            "+------+------+-------+-------------+-----+-----------+--------------+\n",
            "| young|  high|     no|         fair|   no|        1.0|           1.0|\n",
            "| young|  high|     no|    excellent|   no|        1.0|           1.0|\n",
            "|middle|  high|     no|         fair|  yes|        2.0|           1.0|\n",
            "|senior|medium|     no|         fair|  yes|        0.0|           0.0|\n",
            "|senior|   low|    yes|         fair|  yes|        0.0|           2.0|\n",
            "|senior|   low|    yes|    excellent|   no|        0.0|           2.0|\n",
            "|middle|   low|    yes|    excellent|  yes|        2.0|           2.0|\n",
            "| young|medium|     no|         fair|   no|        1.0|           0.0|\n",
            "| young|   low|    yes|         fair|  yes|        1.0|           2.0|\n",
            "|senior|medium|    yes|         fair|  yes|        0.0|           0.0|\n",
            "| young|medium|    yes|    excellent|  yes|        1.0|           0.0|\n",
            "|middle|medium|     no|    excellent|  yes|        2.0|           0.0|\n",
            "|middle|  high|    yes|         fair|  yes|        2.0|           1.0|\n",
            "|senior|medium|     no|    excellent|   no|        0.0|           0.0|\n",
            "+------+------+-------+-------------+-----+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgqQ8E38YGdd"
      },
      "source": [
        "### IndexToString"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE37hfRNYcg2"
      },
      "source": [
        "from pyspark.ml.feature import IndexToString\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIWFiC4NU8LZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1f4db8-1cb2-47d8-afd2-ac9490d93961"
      },
      "source": [
        "age_rev_indexer = IndexToString(inputCol=age_indexer.getOutputCol(),outputCol='original_age')\n",
        "\n",
        "df_orig_age =age_rev_indexer.transform(df_age_idx)\n",
        "df_orig_age.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+-------------+-----+-----------+------------+\n",
            "|   age|income|student|credit_rating|label|indexed_age|original_age|\n",
            "+------+------+-------+-------------+-----+-----------+------------+\n",
            "| young|  high|     no|         fair|   no|        1.0|       young|\n",
            "| young|  high|     no|    excellent|   no|        1.0|       young|\n",
            "|middle|  high|     no|         fair|  yes|        2.0|      middle|\n",
            "|senior|medium|     no|         fair|  yes|        0.0|      senior|\n",
            "|senior|   low|    yes|         fair|  yes|        0.0|      senior|\n",
            "|senior|   low|    yes|    excellent|   no|        0.0|      senior|\n",
            "|middle|   low|    yes|    excellent|  yes|        2.0|      middle|\n",
            "| young|medium|     no|         fair|   no|        1.0|       young|\n",
            "| young|   low|    yes|         fair|  yes|        1.0|       young|\n",
            "|senior|medium|    yes|         fair|  yes|        0.0|      senior|\n",
            "| young|medium|    yes|    excellent|  yes|        1.0|       young|\n",
            "|middle|medium|     no|    excellent|  yes|        2.0|      middle|\n",
            "|middle|  high|    yes|         fair|  yes|        2.0|      middle|\n",
            "|senior|medium|     no|    excellent|   no|        0.0|      senior|\n",
            "+------+------+-------+-------------+-----+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5E5tjqac9Vg"
      },
      "source": [
        "### one-hot encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziVNnxC8dKti"
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTeSQevLdKHz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qde-cCKbLAM",
        "outputId": "8498bc97-d06c-45f3-b675-d1641636f432"
      },
      "source": [
        "age_onehotenc = OneHotEncoder(inputCol=age_indexer.getOutputCol(),outputCol='cat_age')\n",
        "age_onehotenc.setDropLast(False)\n",
        "df_age_onehot = age_onehotenc.fit(df_age_idx).transform(df_age_idx)\n",
        "df_age_onehot.show()\n",
        "#   .setInputCols(Array(\"indexed_age\", \"indexed_income\"))\n",
        "#   .setOutputCols(Array(\"category_age\", \"category_income\"))\n",
        "#   .setDropLast(false)\n",
        "\n",
        "# val encoded = oneHotEncoder.fit(data).transform(data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+-------------+-----+-----------+-------------+\n",
            "|   age|income|student|credit_rating|label|indexed_age|      cat_age|\n",
            "+------+------+-------+-------------+-----+-----------+-------------+\n",
            "| young|  high|     no|         fair|   no|        1.0|(3,[1],[1.0])|\n",
            "| young|  high|     no|    excellent|   no|        1.0|(3,[1],[1.0])|\n",
            "|middle|  high|     no|         fair|  yes|        2.0|(3,[2],[1.0])|\n",
            "|senior|medium|     no|         fair|  yes|        0.0|(3,[0],[1.0])|\n",
            "|senior|   low|    yes|         fair|  yes|        0.0|(3,[0],[1.0])|\n",
            "|senior|   low|    yes|    excellent|   no|        0.0|(3,[0],[1.0])|\n",
            "|middle|   low|    yes|    excellent|  yes|        2.0|(3,[2],[1.0])|\n",
            "| young|medium|     no|         fair|   no|        1.0|(3,[1],[1.0])|\n",
            "| young|   low|    yes|         fair|  yes|        1.0|(3,[1],[1.0])|\n",
            "|senior|medium|    yes|         fair|  yes|        0.0|(3,[0],[1.0])|\n",
            "| young|medium|    yes|    excellent|  yes|        1.0|(3,[1],[1.0])|\n",
            "|middle|medium|     no|    excellent|  yes|        2.0|(3,[2],[1.0])|\n",
            "|middle|  high|    yes|         fair|  yes|        2.0|(3,[2],[1.0])|\n",
            "|senior|medium|     no|    excellent|   no|        0.0|(3,[0],[1.0])|\n",
            "+------+------+-------+-------------+-----+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NOANmixmkVl"
      },
      "source": [
        "### vector assembler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yac8m9-qiH26"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn25eBlJmnNL",
        "outputId": "45045c6d-c66b-4097-a8cc-d4ba54114fcf"
      },
      "source": [
        "cols = ['indexed_age','indexed_income']\n",
        "vec_assembler = VectorAssembler(inputCols= cols, outputCol= 'ageIncomeVec')\n",
        "\n",
        "df_age_income_vec = vec_assembler.transform(df_age_income_idx)\n",
        "df_age_income_vec.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+-------------+-----+-----------+--------------+------------+\n",
            "|   age|income|student|credit_rating|label|indexed_age|indexed_income|ageIncomeVec|\n",
            "+------+------+-------+-------------+-----+-----------+--------------+------------+\n",
            "| young|  high|     no|         fair|   no|        1.0|           1.0|   [1.0,1.0]|\n",
            "| young|  high|     no|    excellent|   no|        1.0|           1.0|   [1.0,1.0]|\n",
            "|middle|  high|     no|         fair|  yes|        2.0|           1.0|   [2.0,1.0]|\n",
            "|senior|medium|     no|         fair|  yes|        0.0|           0.0|   (2,[],[])|\n",
            "|senior|   low|    yes|         fair|  yes|        0.0|           2.0|   [0.0,2.0]|\n",
            "|senior|   low|    yes|    excellent|   no|        0.0|           2.0|   [0.0,2.0]|\n",
            "|middle|   low|    yes|    excellent|  yes|        2.0|           2.0|   [2.0,2.0]|\n",
            "| young|medium|     no|         fair|   no|        1.0|           0.0|   [1.0,0.0]|\n",
            "| young|   low|    yes|         fair|  yes|        1.0|           2.0|   [1.0,2.0]|\n",
            "|senior|medium|    yes|         fair|  yes|        0.0|           0.0|   (2,[],[])|\n",
            "| young|medium|    yes|    excellent|  yes|        1.0|           0.0|   [1.0,0.0]|\n",
            "|middle|medium|     no|    excellent|  yes|        2.0|           0.0|   [2.0,0.0]|\n",
            "|middle|  high|    yes|         fair|  yes|        2.0|           1.0|   [2.0,1.0]|\n",
            "|senior|medium|     no|    excellent|   no|        0.0|           0.0|   (2,[],[])|\n",
            "+------+------+-------+-------------+-----+-----------+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMtNbOVtpAQy"
      },
      "source": [
        "### Vector Indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfWIwP6XrLSN"
      },
      "source": [
        "from pyspark.ml.feature import VectorIndexer\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNgrnoTNnKsB",
        "outputId": "7203ce3c-6665-46dc-cddc-ecf4bd2110f3"
      },
      "source": [
        "vecIndexer = VectorIndexer(inputCol='ageIncomeVec',\\\n",
        "                           outputCol='indexed_ageIncomeVec',\\\n",
        "                           maxCategories=3)\n",
        "df_age_income_vec_idx = vecIndexer.fit(df_age_income_vec).\\\n",
        "    transform(df_age_income_vec)\n",
        "\n",
        "df_age_income_vec_idx.show()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+-------------+-----+-----------+--------------+------------+--------------------+\n",
            "|   age|income|student|credit_rating|label|indexed_age|indexed_income|ageIncomeVec|indexed_ageIncomeVec|\n",
            "+------+------+-------+-------------+-----+-----------+--------------+------------+--------------------+\n",
            "| young|  high|     no|         fair|   no|        1.0|           1.0|   [1.0,1.0]|           [1.0,1.0]|\n",
            "| young|  high|     no|    excellent|   no|        1.0|           1.0|   [1.0,1.0]|           [1.0,1.0]|\n",
            "|middle|  high|     no|         fair|  yes|        2.0|           1.0|   [2.0,1.0]|           [2.0,1.0]|\n",
            "|senior|medium|     no|         fair|  yes|        0.0|           0.0|   (2,[],[])|           (2,[],[])|\n",
            "|senior|   low|    yes|         fair|  yes|        0.0|           2.0|   [0.0,2.0]|           [0.0,2.0]|\n",
            "|senior|   low|    yes|    excellent|   no|        0.0|           2.0|   [0.0,2.0]|           [0.0,2.0]|\n",
            "|middle|   low|    yes|    excellent|  yes|        2.0|           2.0|   [2.0,2.0]|           [2.0,2.0]|\n",
            "| young|medium|     no|         fair|   no|        1.0|           0.0|   [1.0,0.0]|           [1.0,0.0]|\n",
            "| young|   low|    yes|         fair|  yes|        1.0|           2.0|   [1.0,2.0]|           [1.0,2.0]|\n",
            "|senior|medium|    yes|         fair|  yes|        0.0|           0.0|   (2,[],[])|           (2,[],[])|\n",
            "| young|medium|    yes|    excellent|  yes|        1.0|           0.0|   [1.0,0.0]|           [1.0,0.0]|\n",
            "|middle|medium|     no|    excellent|  yes|        2.0|           0.0|   [2.0,0.0]|           [2.0,0.0]|\n",
            "|middle|  high|    yes|         fair|  yes|        2.0|           1.0|   [2.0,1.0]|           [2.0,1.0]|\n",
            "|senior|medium|     no|    excellent|   no|        0.0|           0.0|   (2,[],[])|           (2,[],[])|\n",
            "+------+------+-------+-------------+-----+-----------+--------------+------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIlplaNGt90T"
      },
      "source": [
        "## Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmpF_U7w0311"
      },
      "source": [
        "#### string indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhCTtbdCr_Ig"
      },
      "source": [
        "label = 'label'\n",
        "features_col = data.columns\n",
        "features_col.remove(label)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoxhCjhxxshT"
      },
      "source": [
        "prefix = 'indexed_'"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLLssChaz-I1"
      },
      "source": [
        "label_string_indexer = StringIndexer(inputCol=label, outputCol=prefix+label)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qRwqs7DzA__"
      },
      "source": [
        "features_str_col = list(map(lambda c:prefix+c, features_col))\n",
        "features_string_indexer = StringIndexer(inputCols=features_col,outputCols=features_str_col)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUfcmajh054k"
      },
      "source": [
        "#### vector assembler and indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdg-KL6J0OJQ"
      },
      "source": [
        "vec_assembler = VectorAssembler(inputCols= features_string_indexer.getOutputCols(), outputCol= 'vector')\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIT9jyQw1iXi"
      },
      "source": [
        "vec_indexer = VectorIndexer(inputCol='vector',\\\n",
        "                            outputCol='features',\\\n",
        "                           maxCategories=3)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyr9-SBC0_pT"
      },
      "source": [
        "#### pipeline building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX1OSzVl198X"
      },
      "source": [
        "stages = [label_string_indexer,features_string_indexer,vec_assembler,vec_indexer]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pes-99Ap0_Wb"
      },
      "source": [
        "from pyspark.ml import Pipeline\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erHGu8Bp1yx2",
        "outputId": "5ece0c3b-a378-48bc-db57-17f7e1ba9c41"
      },
      "source": [
        "pipeline = Pipeline(stages = stages)\n",
        "train_data = pipeline.fit(data).transform(data).select(\"features\",\"indexed_label\")\n",
        "train_data.show()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|         features|indexed_label|\n",
            "+-----------------+-------------+\n",
            "|[1.0,1.0,0.0,0.0]|          1.0|\n",
            "|[1.0,1.0,0.0,1.0]|          1.0|\n",
            "|[2.0,1.0,0.0,0.0]|          0.0|\n",
            "|        (4,[],[])|          0.0|\n",
            "|[0.0,2.0,1.0,0.0]|          0.0|\n",
            "|[0.0,2.0,1.0,1.0]|          1.0|\n",
            "|[2.0,2.0,1.0,1.0]|          0.0|\n",
            "|    (4,[0],[1.0])|          1.0|\n",
            "|[1.0,2.0,1.0,0.0]|          0.0|\n",
            "|    (4,[2],[1.0])|          0.0|\n",
            "|[1.0,0.0,1.0,1.0]|          0.0|\n",
            "|[2.0,0.0,0.0,1.0]|          0.0|\n",
            "|[2.0,1.0,1.0,0.0]|          0.0|\n",
            "|    (4,[3],[1.0])|          1.0|\n",
            "+-----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKjgQqxo-3wy"
      },
      "source": [
        "## DT inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4lTg1kL2Q5f"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassificationModel, DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhFagPx2-6Ub",
        "outputId": "bab21556-8e17-4c09-a48e-9dbb2fb9f113"
      },
      "source": [
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol= \"indexed_label\")\n",
        "dtModel = dt.fit(train_data)\n",
        "dtModel"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_d5714bec2c7e, depth=4, numNodes=13, numClasses=2, numFeatures=4"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80sLZK5uAWop",
        "outputId": "92ffaf1c-c9e0-4be5-d3ff-0a8f58c68ebf"
      },
      "source": [
        "print(dtModel.toDebugString)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_d5714bec2c7e, depth=4, numNodes=13, numClasses=2, numFeatures=4\n",
            "  If (feature 0 in {2.0})\n",
            "   Predict: 0.0\n",
            "  Else (feature 0 not in {2.0})\n",
            "   If (feature 2 in {1.0})\n",
            "    If (feature 3 in {0.0})\n",
            "     Predict: 0.0\n",
            "    Else (feature 3 not in {0.0})\n",
            "     If (feature 0 in {1.0})\n",
            "      Predict: 0.0\n",
            "     Else (feature 0 not in {1.0})\n",
            "      Predict: 1.0\n",
            "   Else (feature 2 not in {1.0})\n",
            "    If (feature 0 in {0.0})\n",
            "     If (feature 3 in {0.0})\n",
            "      Predict: 0.0\n",
            "     Else (feature 3 not in {0.0})\n",
            "      Predict: 1.0\n",
            "    Else (feature 0 not in {0.0})\n",
            "     Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wluWPgjzB3BE"
      },
      "source": [
        "## Model Selection and Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9lYeEW0B-Rr"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nr4UzQ6CAQ2",
        "outputId": "b2e9216a-2870-4891-e6f2-4d8658824d88"
      },
      "source": [
        "\n",
        "dt_paramGrid = ParamGridBuilder()\\\n",
        "        .addGrid(dt.maxBins, [40,42])\\\n",
        "        .addGrid(dt.minInstancesPerNode, [10,100]) \\\n",
        "        .build()\n",
        "dt_paramGrid"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
              "  Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10},\n",
              " {Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
              "  Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 100},\n",
              " {Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 42,\n",
              "  Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10},\n",
              " {Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 42,\n",
              "  Param(parent='DecisionTreeClassifier_d5714bec2c7e', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 100}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DmryGJwIZiy"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Use BinaryClassificationEvaluator to evaluate our model\n",
        "evaluatorPR = BinaryClassificationEvaluator(labelCol = \"indexed_label\", rawPredictionCol = \"prediction\", metricName = \"areaUnderPR\")\n",
        "evaluatorAUC = BinaryClassificationEvaluator(labelCol = \"indexed_label\", rawPredictionCol = \"prediction\", metricName = \"areaUnderROC\")\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPkECWLFGi-"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psczK_-hCdWe"
      },
      "source": [
        "# Build out the cross validation\n",
        "\n",
        "#create k folds with k=5.\n",
        "cv = CrossValidator(estimator=dt, \\\n",
        "                    estimatorParamMaps=dt_paramGrid, \\\n",
        "                    evaluator=evaluatorPR, \\\n",
        "                    numFolds=5, \\\n",
        "                    parallelism=2)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfzYAaaGExZa"
      },
      "source": [
        "cvModel = cv.fit(train_data)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmxjG7vjG1Jy",
        "outputId": "62d84178-53ad-4c30-b875-e32774fb0b6d"
      },
      "source": [
        "bestModel = cvModel.bestModel\n",
        "print(bestModel.toDebugString)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_d5714bec2c7e, depth=0, numNodes=1, numClasses=2, numFeatures=4\n",
            "  Predict: 0.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i6NaJPAI7N7",
        "outputId": "28623b58-b508-4829-e1e0-6a370cb3c429"
      },
      "source": [
        "train_pred = cvModel.transform(train_data)\n",
        "train_pred.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+-------------+--------------------+----------+\n",
            "|         features|indexed_label|rawPrediction|         probability|prediction|\n",
            "+-----------------+-------------+-------------+--------------------+----------+\n",
            "|[1.0,1.0,0.0,0.0]|          1.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[1.0,1.0,0.0,1.0]|          1.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[2.0,1.0,0.0,0.0]|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|        (4,[],[])|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[0.0,2.0,1.0,0.0]|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[0.0,2.0,1.0,1.0]|          1.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[2.0,2.0,1.0,1.0]|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|    (4,[0],[1.0])|          1.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[1.0,2.0,1.0,0.0]|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|    (4,[2],[1.0])|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[1.0,0.0,1.0,1.0]|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[2.0,0.0,0.0,1.0]|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|[2.0,1.0,1.0,0.0]|          0.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "|    (4,[3],[1.0])|          1.0|    [9.0,5.0]|[0.64285714285714...|       0.0|\n",
            "+-----------------+-------------+-------------+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvDVyDFBJUlC"
      },
      "source": [],
      "execution_count": 42,
      "outputs": []
    }
  ]
}